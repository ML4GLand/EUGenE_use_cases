{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scBasset on PBMC dataset described at scBasset GitHub page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "import psutil\n",
    "import anndata\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "# see ig GPU is available\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generator to read examples from h5 file\n",
    "# create a tf dataset\n",
    "class generator:\n",
    "    def __init__(self, file, m):\n",
    "        self.file = file # h5 file for sequence\n",
    "        self.m = m # csr matrix, rows as seqs, cols are cells\n",
    "        self.n_cells = m.shape[1]\n",
    "        self.ones = np.ones(1344)\n",
    "        self.rows = np.arange(1344)\n",
    "\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as hf:\n",
    "            X = hf['X']\n",
    "            for i in range(X.shape[0]):\n",
    "                x = X[i]\n",
    "                x_tf = sparse.coo_matrix((self.ones, (self.rows, x)), \n",
    "                                               shape=(1344, 4), \n",
    "                                               dtype='int8').toarray()\n",
    "                y = self.m.indices[self.m.indptr[i]:self.m.indptr[i+1]]\n",
    "                y_tf = np.zeros(self.n_cells, dtype='int8')\n",
    "                y_tf[y] = 1\n",
    "                yield x_tf, y_tf\n",
    "\n",
    "def print_memory():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print('cpu memory used: %.1fGB.'%(process.memory_info().rss/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/cellar/users/aklie/projects/ML4GLand/use_cases/scBasset/pbmc-granulocyte-sorted-3k_10x-Multiome/processed'\n",
    "split_file = os.path.join(input_dir, 'splits.h5')\n",
    "train_file = os.path.join(input_dir, 'train_seqs.h5')\n",
    "val_file = os.path.join(input_dir, 'val_seqs.h5')\n",
    "test_file = os.path.join(input_dir, 'test_seqs.h5')\n",
    "ad_file = os.path.join(input_dir, 'atac_ad.h5ad')\n",
    "output_dir = '/cellar/users/aklie/projects/ML4GLand/use_cases/scBasset/pbmc-granulocyte-sorted-3k_10x-Multiome/model'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the sparse matrix from the anndata object\n",
    "adata = anndata.read_h5ad(ad_file)\n",
    "n_cells = adata.shape[0]\n",
    "m = adata.X.tocoo().transpose().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_memory()     # memory usage\n",
    "del adata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the splits\n",
    "with h5py.File(split_file, 'r') as hf:\n",
    "    train_ids = hf['train_ids'][:]\n",
    "    val_ids = hf['val_ids'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and val\n",
    "m_train = m[train_ids,:]\n",
    "m_val = m[val_ids,:]\n",
    "del m\n",
    "gc.collect()\n",
    "m_train.shape, m_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf datasets\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "     generator(train_file, m_train), \n",
    "     output_signature=(\n",
    "          tf.TensorSpec(shape=(1344,4), dtype=tf.int8),\n",
    "          tf.TensorSpec(shape=(n_cells), dtype=tf.int8),\n",
    "     )\n",
    ").shuffle(2000, reshuffle_each_iteration=True).batch(128).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_generator(\n",
    "     generator(val_file, m_val), \n",
    "     output_signature=(\n",
    "          tf.TensorSpec(shape=(1344,4), dtype=tf.int8),\n",
    "          tf.TensorSpec(shape=(n_cells), dtype=tf.int8),\n",
    "     )\n",
    ").batch(128).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an example batch from training dataset\n",
    "for x, y in train_ds.take(1):\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an scBasset model with their code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scbasset.utils import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(32, n_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss, optimizer, and compile the mdodel\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01,beta_1=0.95,beta_2=0.9995)\n",
    "model.compile(\n",
    "    loss=loss_fn, \n",
    "    optimizer=optimizer,\n",
    "    metrics=[tf.keras.metrics.AUC(curve='ROC', multi_label=True),\n",
    "    tf.keras.metrics.AUC(curve='PR', multi_label=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earlystopping, track train AUC\n",
    "filepath = os.path.join(output_dir, 'best_model.h5')\n",
    "    \n",
    "# tensorboard\n",
    "logs = os.path.join(output_dir, \"logs\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(output_dir)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=True, \n",
    "    monitor='auc', \n",
    "    mode='max'\n",
    ")\n",
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='auc', \n",
    "    min_delta=1e-6, \n",
    "    mode='max', \n",
    "    patience=50, \n",
    "    verbose=1\n",
    ")\n",
    "callbacks = [tensorboard_callback, checkpoint_callback, earlystopping_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/217 [============================>.] - ETA: 0s - loss: 0.3901 - auc_2: 0.7614 - auc_3: 0.4191WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3901 - auc_2: 0.7613 - auc_3: 0.4190 - val_loss: 0.4007 - val_auc_2: 0.7390 - val_auc_3: 0.3822\n",
      "Epoch 20/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3892 - auc_2: 0.7631 - auc_3: 0.4205WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3892 - auc_2: 0.7631 - auc_3: 0.4204 - val_loss: 0.4007 - val_auc_2: 0.7390 - val_auc_3: 0.3862\n",
      "Epoch 21/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3883 - auc_2: 0.7646 - auc_3: 0.4222WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3883 - auc_2: 0.7647 - auc_3: 0.4222 - val_loss: 0.4026 - val_auc_2: 0.7362 - val_auc_3: 0.3791\n",
      "Epoch 22/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3871 - auc_2: 0.7667 - auc_3: 0.4258WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3871 - auc_2: 0.7667 - auc_3: 0.4257 - val_loss: 0.4037 - val_auc_2: 0.7375 - val_auc_3: 0.3866\n",
      "Epoch 23/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3864 - auc_2: 0.7681 - auc_3: 0.4260WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3864 - auc_2: 0.7681 - auc_3: 0.4260 - val_loss: 0.3994 - val_auc_2: 0.7412 - val_auc_3: 0.3889\n",
      "Epoch 24/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3851 - auc_2: 0.7701 - auc_3: 0.4288WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3852 - auc_2: 0.7701 - auc_3: 0.4288 - val_loss: 0.4029 - val_auc_2: 0.7342 - val_auc_3: 0.3865\n",
      "Epoch 25/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3847 - auc_2: 0.7708 - auc_3: 0.4296WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3848 - auc_2: 0.7708 - auc_3: 0.4297 - val_loss: 0.4008 - val_auc_2: 0.7387 - val_auc_3: 0.3865\n",
      "Epoch 26/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3841 - auc_2: 0.7720 - auc_3: 0.4307WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3841 - auc_2: 0.7720 - auc_3: 0.4307 - val_loss: 0.4032 - val_auc_2: 0.7352 - val_auc_3: 0.3803\n",
      "Epoch 27/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3835 - auc_2: 0.7731 - auc_3: 0.4323WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3835 - auc_2: 0.7731 - auc_3: 0.4322 - val_loss: 0.3992 - val_auc_2: 0.7381 - val_auc_3: 0.3852\n",
      "Epoch 28/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.3830 - auc_2: 0.7741 - auc_3: 0.4328WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 24s 107ms/step - loss: 0.3830 - auc_2: 0.7740 - auc_3: 0.4327 - val_loss: 0.4022 - val_auc_2: 0.7394 - val_auc_3: 0.3831\n",
      "Epoch 29/1000\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4161 - auc_2: 0.6927 - auc_3: 0.3610WARNING:tensorflow:Can save best model only with auc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `auc` which is not available. Available metrics are: loss,auc_2,auc_3,val_loss,val_auc_2,val_auc_3\n",
      "217/217 [==============================] - 23s 106ms/step - loss: 0.4161 - auc_2: 0.6926 - auc_3: 0.3609 - val_loss: 11.0234 - val_auc_2: 0.5207 - val_auc_3: 0.1896\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 10:34:28.844961: W tensorflow/core/framework/op_kernel.cc:1733] UNKNOWN: KeyError: \"Unable to open object (object 'X' doesn't exist)\"\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/tmp/ipykernel_4095444/344002438.py\", line 13, in __call__\n",
      "    X = hf['X']\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/group.py\", line 305, in __getitem__\n",
      "    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n",
      "\n",
      "KeyError: \"Unable to open object (object 'X' doesn't exist)\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  KeyError: \"Unable to open object (object 'X' doesn't exist)\"\nTraceback (most recent call last):\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_4095444/344002438.py\", line 13, in __call__\n    X = hf['X']\n\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/group.py\", line 305, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n\nKeyError: \"Unable to open object (object 'X' doesn't exist)\"\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[assert_greater_equal_1/Assert/AssertGuard/else/_59/assert_greater_equal_1/Assert/AssertGuard/Assert/data_1/_148]]\n  (1) UNKNOWN:  KeyError: \"Unable to open object (object 'X' doesn't exist)\"\nTraceback (most recent call last):\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_4095444/344002438.py\", line 13, in __call__\n    X = hf['X']\n\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/group.py\", line 305, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n\nKeyError: \"Unable to open object (object 'X' doesn't exist)\"\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_7154]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4095444/3199674448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  KeyError: \"Unable to open object (object 'X' doesn't exist)\"\nTraceback (most recent call last):\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_4095444/344002438.py\", line 13, in __call__\n    X = hf['X']\n\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/group.py\", line 305, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n\nKeyError: \"Unable to open object (object 'X' doesn't exist)\"\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[assert_greater_equal_1/Assert/AssertGuard/else/_59/assert_greater_equal_1/Assert/AssertGuard/Assert/data_1/_148]]\n  (1) UNKNOWN:  KeyError: \"Unable to open object (object 'X' doesn't exist)\"\nTraceback (most recent call last):\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_4095444/344002438.py\", line 13, in __call__\n    X = hf['X']\n\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n\n  File \"/cellar/users/aklie/opt/miniconda3/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/group.py\", line 305, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n\n  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n\nKeyError: \"Unable to open object (object 'X' doesn't exist)\"\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_7154]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=1000,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(history.history, open('%s/history.pickle'%output_dir, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with script "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%bash\n",
    "source activate scbasset\n",
    "python /cellar/users/aklie/opt/ml4gland/scBasset/bin/scbasset_train.py \\\n",
    "    --input_folder /cellar/users/aklie/projects/ML4GLand/use_cases/scBasset/pbmc-granulocyte-sorted-3k_10x-Multiome/processed \\\n",
    "    --out_path /cellar/users/aklie/projects/ML4GLand/use_cases/scBasset/pbmc-granulocyte-sorted-3k_10x-Multiome/model/21Sep23/scbasset/script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 scbasset",
   "language": "python",
   "name": "scbasset"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
