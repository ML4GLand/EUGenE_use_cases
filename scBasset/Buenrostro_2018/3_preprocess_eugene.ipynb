{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare EUGENE SeqData on `Buenrostro_2018` dataset\n",
    "Adam Klie (last updated: *09/20/2023*)\n",
    "***\n",
    "This notebook shows how to take scBasset processed data and convert to EUGENe ready SeqDatas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "import xarray as xr\n",
    "import psutil\n",
    "import anndata\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generator to read examples from h5 file to create a tf dataset\n",
    "class generator:\n",
    "    def __init__(self, file, m):\n",
    "        self.file = file # h5 file for sequence\n",
    "        self.m = m # csr matrix, rows as seqs, cols are cells\n",
    "        self.n_cells = m.shape[1]\n",
    "        self.ones = np.ones(1344)\n",
    "        self.rows = np.arange(1344)\n",
    "\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as hf:\n",
    "            X = hf['X']\n",
    "            for i in range(X.shape[0]):\n",
    "                x = X[i]\n",
    "                x_tf = sparse.coo_matrix((self.ones, (self.rows, x)), \n",
    "                                               shape=(1344, 4), \n",
    "                                               dtype='int8').toarray()\n",
    "                y = self.m.indices[self.m.indptr[i]:self.m.indptr[i+1]]\n",
    "                y_tf = np.zeros(self.n_cells, dtype='int8')\n",
    "                y_tf[y] = 1\n",
    "                yield x_tf, y_tf\n",
    "\n",
    "def print_memory():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print('cpu memory used: %.1fGB.'%(process.memory_info().rss/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up the paths to data (TODO: change to your own paths)\n",
    "input_dir = '/cellar/users/aklie/projects/ML4GLand/use_cases/scBasset/Buenrostro_2018/processed'\n",
    "split_file = os.path.join(input_dir, 'splits.h5')\n",
    "train_file = os.path.join(input_dir, 'train_seqs.h5')\n",
    "val_file = os.path.join(input_dir, 'val_seqs.h5')\n",
    "test_file = os.path.join(input_dir, 'test_seqs.h5')\n",
    "ad_file = os.path.join(input_dir, 'atac_ad.h5ad')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the sparse matrix from the anndata object\n",
    "adata = anndata.read_h5ad(ad_file)\n",
    "n_cells = adata.shape[0]\n",
    "m = adata.X.tocoo().transpose().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu memory used: 1.2GB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check memory usage\n",
    "print_memory()\n",
    "del adata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the splits\n",
    "with h5py.File(split_file, 'r') as hf:\n",
    "    train_ids = hf['train_ids'][:]\n",
    "    val_ids = hf['val_ids'][:]\n",
    "    test_ids = hf['test_ids'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27677, 2711), (1537, 2711))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and val\n",
    "m_train = m[train_ids,:]\n",
    "m_val = m[val_ids,:]\n",
    "m_test = m[test_ids,:]\n",
    "del m\n",
    "gc.collect()\n",
    "m_train.shape, m_val.shape, m_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf datasets\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "     generator(train_file, m_train), \n",
    "     output_signature=(\n",
    "          tf.TensorSpec(shape=(1344,4), dtype=tf.int8),\n",
    "          tf.TensorSpec(shape=(n_cells), dtype=tf.int8),\n",
    "     )\n",
    ").batch(m_train.shape[0])\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "     generator(val_file, m_val), \n",
    "     output_signature=(\n",
    "          tf.TensorSpec(shape=(1344,4), dtype=tf.int8),\n",
    "          tf.TensorSpec(shape=(n_cells), dtype=tf.int8),\n",
    "     )\n",
    ").batch(m_val.shape[0])\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "     generator(test_file, m_test),\n",
    "     output_signature=(\n",
    "          tf.TensorSpec(shape=(1344,4), dtype=tf.int8),\n",
    "          tf.TensorSpec(shape=(n_cells), dtype=tf.int8),\n",
    "     )\n",
    ").batch(m_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1537, 1344, 4) (1537, 2711)\n"
     ]
    }
   ],
   "source": [
    "# Create the train seqdata\n",
    "x_train, y_train = train_ds.take(1)\n",
    "train_ohe_seq_xr = xr.DataArray(\n",
    "    x_train.numpy(),\n",
    "    dims=['_sequence', '_length', '_ohe'], \n",
    "    name='ohe_seq'\n",
    ")\n",
    "train_bin_counts_xr = xr.DataArray(\n",
    "    y_train.numpy(),\n",
    "    dims=['_sequence', '_target'],\n",
    "    name='bin_counts'\n",
    ")\n",
    "sdata_train = xr.Dataset({'ohe_seq': train_ohe_seq_xr, 'bin_counts': train_bin_counts_xr})\n",
    "\n",
    "# Create the val seqdata\n",
    "x_val, y_val = val_ds.take(1)\n",
    "val_ohe_seq_xr = xr.DataArray(\n",
    "    x_val.numpy(),\n",
    "    dims=['_sequence', '_length', '_ohe'],\n",
    "    name='ohe_seq'\n",
    ")\n",
    "val_bin_counts_xr = xr.DataArray(\n",
    "    y_val.numpy(),\n",
    "    dims=['_sequence', '_target'],\n",
    "    name='bin_counts'\n",
    ")\n",
    "sdata_val = xr.Dataset({'ohe_seq': val_ohe_seq_xr, 'bin_counts': val_bin_counts_xr})\n",
    "\n",
    "# Create the test seqdata\n",
    "x_test, y_test = test_ds.take(1)\n",
    "test_ohe_seq_xr = xr.DataArray(\n",
    "    x_test.numpy(),\n",
    "    dims=['_sequence', '_length', '_ohe'],\n",
    "    name='ohe_seq'\n",
    ")\n",
    "test_bin_counts_xr = xr.DataArray(\n",
    "    y_test.numpy(),\n",
    "    dims=['_sequence', '_target'],\n",
    "    name='bin_counts'\n",
    ")\n",
    "sdata_test = xr.Dataset({'ohe_seq': test_ohe_seq_xr, 'bin_counts': test_bin_counts_xr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each to zarr\n",
    "sdata_train.to_zarr(os.path.join(input_dir, 'train_seqdata.zarr'))\n",
    "sdata_val.to_zarr(os.path.join(input_dir, 'val_seqdata.zarr'))\n",
    "sdata_test.to_zarr(os.path.join(input_dir, 'test_seqdata.zarr'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
