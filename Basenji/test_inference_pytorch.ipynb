{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing PyTorch Basenji2 for inference\n",
    "Adam Klie (last updated: *07/19/2023*)\n",
    "***\n",
    "Test the PyTorch implementation of Basenji2 for inference on some randomly generated sequences. This is a good place to check if your installation is working properly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "# In case the PYTHONPATH is not set\n",
    "import sys\n",
    "sys.path.append('/cellar/users/aklie/opt/ml4gland/basenji2-pytorch')\n",
    "\n",
    "# Clean cuda mem\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the code for loading the PyTorch model\n",
    "from basenji2_pytorch import Basenji2, params # or PLBasenji2 to use training parameters from Kelley et al. 2020\n",
    "\n",
    "# Define the path to your downloaded weights\n",
    "model_weights = '/cellar/users/aklie/projects/ML4GLand/models/Basenji/basenji2.pth'  # TODO: Change this to your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the model config file\n",
    "with open(params) as params_open:\n",
    "    params = json.load(params_open)\n",
    "    model_params = params['model']\n",
    "    train_params = params['train']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "basenji2 = Basenji2(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "basenji2.load_state_dict(torch.load(model_weights), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "torchinfo.summary(basenji2, input_size=(1, 4, 131072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send Basenji2 to CPU and capture the output\n",
    "basenji2.cpu().eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test inference on single sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seqpro as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random sequence\n",
    "seqs = sp.random_seqs((1, 131072), sp.alphabets.DNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the sequence and make it a PyTorch tensor\n",
    "ohe_seqs = torch.tensor(sp.ohe(seqs, alphabet=sp.alphabets.DNA), dtype=torch.float32).permute(0, 2, 1).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how big this sequence is in memory\n",
    "print(f\"Size of sequence in memory: {ohe_seqs.element_size() * ohe_seqs.nelement() / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sequence through the model\n",
    "basenji2(ohe_seqs).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
