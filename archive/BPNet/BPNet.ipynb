{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Using EUGENe to generate a BPNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T02:11:13.304987Z",
     "iopub.status.busy": "2023-03-28T02:11:13.304383Z",
     "iopub.status.idle": "2023-03-28T02:11:13.349150Z",
     "shell.execute_reply": "2023-03-28T02:11:13.347668Z",
     "shell.execute_reply.started": "2023-03-28T02:11:13.304870Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio import motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T02:11:13.358318Z",
     "iopub.status.busy": "2023-03-28T02:11:13.357855Z",
     "iopub.status.idle": "2023-03-28T02:11:13.444151Z",
     "shell.execute_reply": "2023-03-28T02:11:13.442963Z",
     "shell.execute_reply.started": "2023-03-28T02:11:13.358282Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio.motifs import jaspar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T02:11:13.449240Z",
     "iopub.status.busy": "2023-03-28T02:11:13.448849Z",
     "iopub.status.idle": "2023-03-28T02:12:00.000805Z",
     "shell.execute_reply": "2023-03-28T02:11:59.998965Z",
     "shell.execute_reply.started": "2023-03-28T02:11:13.449205Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import eugene as eu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProfileDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T02:12:00.008792Z",
     "iopub.status.busy": "2023-03-28T02:12:00.008347Z",
     "iopub.status.idle": "2023-03-28T02:12:00.018110Z",
     "shell.execute_reply": "2023-03-28T02:12:00.016588Z",
     "shell.execute_reply.started": "2023-03-28T02:12:00.008756Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "data_dir = \"/cellar/users/aklie/data/eugene/avsec21/ENCSR000EGM/data\"\n",
    "reference_dir = \"/cellar/users/aklie/data/eugene/avsec21/reference\"\n",
    "peaks = os.path.join(data_dir, \"peaks.bed\")\n",
    "#peaks = \"/cellar/users/aklie/data/eugene/avsec21/ENCSR000EGM/toy.bed\"\n",
    "seqs = os.path.join(reference_dir, \"hg38.fa\")\n",
    "signals = [os.path.join(data_dir, \"plus.bw\"), os.path.join(data_dir, \"minus.bw\")]\n",
    "controls = [os.path.join(data_dir, \"control_plus.bw\"), os.path.join(data_dir, \"control_minus.bw\")]\n",
    "\n",
    "# Set training and validation chromosomes\n",
    "training_chroms = ['chr{}'.format(i) for i in range(1, 17)]\n",
    "valid_chroms = ['chr{}'.format(i) for i in range(18, 23)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T02:12:00.023712Z",
     "iopub.status.busy": "2023-03-28T02:12:00.023269Z",
     "iopub.status.idle": "2023-03-28T02:12:00.031388Z",
     "shell.execute_reply": "2023-03-28T02:12:00.030223Z",
     "shell.execute_reply.started": "2023-03-28T02:12:00.023664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from eugene.dataload import ProfileDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T02:12:00.036694Z",
     "iopub.status.busy": "2023-03-28T02:12:00.036276Z",
     "iopub.status.idle": "2023-03-28T02:16:17.275877Z",
     "shell.execute_reply": "2023-03-28T02:16:17.274091Z",
     "shell.execute_reply.started": "2023-03-28T02:12:00.036659Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_ctl_train = eu.dl.read_profile(peaks, seqs, signals, controls, max_jitter=128, chroms=training_chroms)\n",
    "#X_val, y_val, X_ctl_val = eu.dl.read_profile(peaks, seqs, signals, controls, max_jitter=0, chroms=valid_chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T02:18:32.334797Z",
     "iopub.status.busy": "2023-03-28T02:18:32.334254Z",
     "iopub.status.idle": "2023-03-28T02:18:32.354699Z",
     "shell.execute_reply": "2023-03-28T02:18:32.353273Z",
     "shell.execute_reply.started": "2023-03-28T02:18:32.334756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45803, 4, 2370])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_dataset = ProfileDataset(X_train, y_train, X_ctl_train)\n",
    "X_val_dataset = ProfileDataset(X_val, y_val, X_ctl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_loader = X_train_dataset.to_dataloader(batch_size=64, num_workers=4, shuffle=True)\n",
    "X_val_loader = X_val_dataset.to_dataloader(batch_size=64, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eugene.models._profile_models import BPNet\n",
    "\n",
    "model = BPNet(\n",
    "    input_len=2114,\n",
    "    output_dim=1000,\n",
    "    n_outputs=2,\n",
    "    n_control_tracks=2, \n",
    "    trimming=(2114 - 1000) // 2\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2, 1000]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(X_dataloader_val))\n",
    "outs = model(batch[0].cuda(), batch[1].cuda())\n",
    "outs[0].shape, outs[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "logging_dir = \"/cellar/users/aklie/projects/ML4GLand/use_cases/avsec21/\"\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=5, progress_bar_refresh_rate=20, logger=pl.loggers.TensorBoardLogger(logging_dir, name=\"models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Missing logger folder: /cellar/users/aklie/projects/ML4GLand/use_cases/avsec21/bpnet\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | iconv  | Conv1d     | 5.4 K \n",
      "1 | irelu  | ReLU       | 0     \n",
      "2 | rconvs | ModuleList | 98.8 K\n",
      "3 | rrelus | ModuleList | 0     \n",
      "4 | fconv  | Conv1d     | 9.9 K \n",
      "5 | linear | Linear     | 66    \n",
      "--------------------------------------\n",
      "114 K     Trainable params\n",
      "0         Non-trainable params\n",
      "114 K     Total params\n",
      "0.457     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f83374a97e471ca9976d853e48d627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2ffcab79ff448aa4143ff115b3127a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981e295120a14458a2ca93efe0e195e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc3dea164814e0b83ae32d344ed793f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d4f5524edb4964aec51895a813aa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e5eb73dc0946ca856ed908afb14beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2654bc8cd79b41f3b73986f3c74571d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, X_train_loader, X_val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seqexplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mseqexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m      ~/projects/ML4GLand/SeqExplainer/seqexplainer/_feature_attribution.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "seqexplainer.attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4083192/4061347828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"InputXGradient\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ctl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/projects/ML4GLand/SeqExplainer/seqexplainer/_feature_attribution.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(model, inputs, method, target, device, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ML4GLand/SeqExplainer/seqexplainer/_feature_attribution.py\u001b[0m in \u001b[0;36m_captum_attributions\u001b[0;34m(model, inputs, method, target, device, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mattributor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCAPTUM_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattributor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/captum/attr/_core/input_x_gradient.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         gradients = self.gradient_func(\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# runs forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         assert outputs[0].numel() == 1, (\n\u001b[1;32m    114\u001b[0m             \u001b[0;34m\"Target not provided when necessary, cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     )\n\u001b[0;32m--> 461\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_select_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/eugene_dev/lib/python3.7/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m     \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "seqexplainer.attribute(\n",
    "    pretrained_model,\n",
    "    X,\n",
    "    method=\"InputXGradient\",\n",
    "    additional_forward_args=(X_ctl,),\n",
    "    target=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import pyfaidx\n",
    "import pyBigWig\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_loci(\n",
    "\tloci, \n",
    "    sequences, \n",
    "    signals=None, \n",
    "    controls=None, \n",
    "    chroms=None, \n",
    "\tin_window=2114,\n",
    "    out_window=1000, \n",
    "    max_jitter=128, \n",
    "    min_counts=None,\n",
    "\tmax_counts=None, \n",
    "    verbose=False\n",
    "):\n",
    "\t\"\"\"Extract sequences and signals at coordinates from a locus file.\n",
    "\tThis function will take in genome-wide sequences, signals, and optionally\n",
    "\tcontrols, and extract the values of each at the coordinates specified in\n",
    "\tthe locus file/s and return them as tensors.\n",
    "\tSignals and controls are both lists with the length of the list, n_s\n",
    "\tand n_c respectively, being the middle dimension of the returned\n",
    "\ttensors. Specifically, the returned tensors of size \n",
    "\t(len(loci), n_s/n_c, (out_window/in_wndow)+max_jitter*2).\n",
    "\tThe values for sequences, signals, and controls, can either be filepaths\n",
    "\tor dictionaries of np arrays or a mix of the two. When a filepath is \n",
    "\tpassed in it is loaded using pyfaidx or pyBigWig respectively.   \n",
    "\tParameters\n",
    "\t----------\n",
    "\tloci: str or pd.DataFrame or list/tuple of such\n",
    "\t\tEither the path to a bed file or a pd DataFrame object containing\n",
    "\t\tthree columns: the chromosome, the start, and the end, of each locus\n",
    "\t\tto train on. Alternatively, a list or tuple of strings/DataFrames where\n",
    "\t\tthe intention is to train on the interleaved concatenation, i.e., when\n",
    "\t\tyou want to train on peaks and negatives.\n",
    "\tsequences: str or dictionary\n",
    "\t\tEither the path to a fasta file to read from or a dictionary where the\n",
    "\t\tkeys are the unique set of chromosoms and the values are one-hot\n",
    "\t\tencoded sequences as np arrays or memory maps.\n",
    "\tsignals: list of strs or list of dictionaries or None, optional\n",
    "\t\tA list of filepaths to bigwig files, where each filepath will be read\n",
    "\t\tusing pyBigWig, or a list of dictionaries where the keys are the same\n",
    "\t\tset of unique chromosomes and the values are np arrays or memory\n",
    "\t\tmaps. If None, no signal tensor is returned. Default is None.\n",
    "\tcontrols: list of strs or list of dictionaries or None, optional\n",
    "\t\tA list of filepaths to bigwig files, where each filepath will be read\n",
    "\t\tusing pyBigWig, or a list of dictionaries where the keys are the same\n",
    "\t\tset of unique chromosomes and the values are np arrays or memory\n",
    "\t\tmaps. If None, no control tensor is returned. Default is None. \n",
    "\tchroms: list or None, optional\n",
    "\t\tA set of chromosomes to extact loci from. Loci in other chromosomes\n",
    "\t\tin the locus file are ignored. If None, all loci are used. Default is\n",
    "\t\tNone.\n",
    "\tin_window: int, optional\n",
    "\t\tThe input window size. Default is 2114.\n",
    "\tout_window: int, optional\n",
    "\t\tThe output window size. Default is 1000.\n",
    "\tmax_jitter: int, optional\n",
    "\t\tThe maximum amount of jitter to add, in either direction, to the\n",
    "\t\tmidpoints that are passed in. Default is 128.\n",
    "\tmin_counts: float or None, optional\n",
    "\t\tThe minimum number of counts, summed across the length of each example\n",
    "\t\tand across all tasks, needed to be kept. If None, no minimum. Default \n",
    "\t\tis None.\n",
    "\tmax_counts: float or None, optional\n",
    "\t\tThe maximum number of counts, summed across the length of each example\n",
    "\t\tand across all tasks, needed to be kept. If None, no maximum. Default \n",
    "\t\tis None.  \n",
    "\tverbose: bool, optional\n",
    "\t\tWhether to display a progress bar while loading. Default is False.\n",
    "\tReturns\n",
    "\t-------\n",
    "\tseqs: torch.tensor, shape=(n, 4, in_window+2*max_jitter)\n",
    "\t\tThe extracted sequences in the same order as the loci in the locus\n",
    "\t\tfile after optional filtering by chromosome.\n",
    "\tsignals: torch.tensor, shape=(n, len(signals), out_window+2*max_jitter)\n",
    "\t\tThe extracted signals where the first dimension is in the same order\n",
    "\t\tas loci in the locus file after optional filtering by chromosome and\n",
    "\t\tthe second dimension is in the same order as the list of signal files.\n",
    "\t\tIf no signal files are given, this is not returned.\n",
    "\tcontrols: torch.tensor, shape=(n, len(controls), out_window+2*max_jitter)\n",
    "\t\tThe extracted controls where the first dimension is in the same order\n",
    "\t\tas loci in the locus file after optional filtering by chromosome and\n",
    "\t\tthe second dimension is in the same order as the list of control files.\n",
    "\t\tIf no control files are given, this is not returned.\n",
    "\t\"\"\"\n",
    "\n",
    "\tseqs, signals_, controls_ = [], [], []\n",
    "\tin_width, out_width = in_window // 2, out_window // 2\n",
    "\n",
    "\t# Load the sequences\n",
    "\tif isinstance(sequences, str):\n",
    "\t\tsequences = pyfaidx.Fasta(sequences)\n",
    "\n",
    "\tnames = ['chrom', 'start', 'end']\n",
    "\tif not isinstance(loci, (tuple, list)):\n",
    "\t\tloci = [loci]\n",
    "\n",
    "\tloci_dfs = []\n",
    "\tfor i, df in enumerate(loci):\n",
    "\t\tif isinstance(df, str):\n",
    "\t\t\tdf = pd.read_csv(df, sep='\\t', usecols=[0, 1, 2], header=None, index_col=False, names=names)\n",
    "\t\t\tdf['idx'] = np.arange(len(df)) * len(loci) + i\n",
    "\t\tloci_dfs.append(df)\n",
    "\n",
    "\tloci = pd.concat(loci_dfs).set_index(\"idx\").sort_index().reset_index(drop=True)\n",
    "\tif chroms is not None:\n",
    "\t\tloci = loci[np.isin(loci['chrom'], chroms)]\n",
    "\n",
    "\t# Load the signal and optional control tracks if filenames are given\n",
    "\tif signals is not None:\n",
    "\t\tfor i, signal in enumerate(signals):\n",
    "\t\t\tif isinstance(signal, str):\n",
    "\t\t\t\tsignals[i] = pyBigWig.open(signal, \"r\")\n",
    "\n",
    "\tif controls is not None:\n",
    "\t\tfor i, control in enumerate(controls):\n",
    "\t\t\tif isinstance(control, str):\n",
    "\t\t\t\tcontrols[i] = pyBigWig.open(control, \"r\")\n",
    "\n",
    "\tdesc = \"Loading Loci\"\n",
    "\td = not verbose\n",
    "\n",
    "\tmax_width = max(in_width, out_width)\n",
    "\n",
    "\tfor chrom, start, end in tqdm(loci.values, disable=d, desc=desc):\n",
    "\t\tmid = start + (end - start) // 2\n",
    "\n",
    "\t\tif start - max_width - max_jitter < 0:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tif end + max_width + max_jitter >= len(sequences[chrom]):\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\tstart = mid - out_width - max_jitter\n",
    "\t\tend = mid + out_width + max_jitter\n",
    "\t\t\n",
    "\t\t# Extract the signal from each of the signal files\n",
    "\t\tif signals is not None:\n",
    "\t\t\tsignals_.append([])\n",
    "\t\t\tfor signal in signals:\n",
    "\t\t\t\tif isinstance(signal, dict):\n",
    "\t\t\t\t\tsignal_ = signal[chrom][start:end]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsignal_ = signal.values(chrom, start, end, numpy=True)\n",
    "\t\t\t\t\tsignal_ = np.nan_to_num(signal_)\n",
    "\n",
    "\t\t\t\tsignals_[-1].append(signal_)\n",
    "\n",
    "\t\t# For the sequences and controls extract a window the size of the input\n",
    "\t\tstart = mid - in_width - max_jitter\n",
    "\t\tend = mid + in_width + max_jitter\n",
    "\n",
    "\t\t# Extract the controls from each of the control files\n",
    "\t\tif controls is not None:\n",
    "\t\t\tcontrols_.append([])\n",
    "\t\t\tfor control in controls:\n",
    "\t\t\t\tif isinstance(control, dict):\n",
    "\t\t\t\t\tcontrol_ = control[chrom][start:end]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcontrol_ = control.values(chrom, start, end, numpy=True)\n",
    "\t\t\t\t\tcontrol_ = np.nan_to_num(control_)\n",
    "\n",
    "\t\t\t\tcontrols_[-1].append(control_)\n",
    "\n",
    "\t\t# Extract the sequence\n",
    "\t\tif isinstance(sequences, dict):\n",
    "\t\t\tseq = sequences[chrom][start:end].T\n",
    "\t\telse:\n",
    "\t\t\tseq = eu.pp.ohe_seq(sequences[chrom][start:end].seq.upper())\n",
    "\t\t\n",
    "\t\tseqs.append(seq)\n",
    "\n",
    "\tseqs = torch.tensor(np.array(seqs), dtype=torch.float32)\n",
    "\n",
    "\tif signals is not None:\n",
    "\t\tsignals_ = torch.tensor(np.array(signals_), dtype=torch.float32)\n",
    "\n",
    "\t\tidxs = torch.ones(signals_.shape[0], dtype=torch.bool)\n",
    "\t\tif max_counts is not None:\n",
    "\t\t\tidxs = (idxs) & (signals_.sum(dim=(1, 2)) < max_counts)\n",
    "\t\tif min_counts is not None:\n",
    "\t\t\tidxs = (idxs) & (signals_.sum(dim=(1, 2)) > min_counts)\n",
    "\n",
    "\t\tif controls is not None:\n",
    "\t\t\tcontrols_ = torch.tensor(np.array(controls_), dtype=torch.float32)\n",
    "\t\t\treturn seqs[idxs], signals_[idxs], controls_[idxs]\n",
    "\n",
    "\t\treturn seqs[idxs], signals_[idxs]\n",
    "\telse:\n",
    "\t\tif controls is not None:\n",
    "\t\t\tcontrols_ = torch.tensor(np.array(controls_), dtype=torch.float32)\n",
    "\t\t\treturn seqs, controls_\n",
    "\n",
    "\t\treturn seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_toy, y_toy, X_ctl_toy = extract_loci(peaks, seqs, signals, controls, max_jitter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 4, 2114]),\n",
       " torch.Size([100, 2, 1000]),\n",
       " torch.Size([100, 2, 2114]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_toy.shape, y_toy.shape, X_ctl_toy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ProfileDataset(Dataset):\n",
    "\t\"\"\"A data generator for BPNet inputs.\n",
    "\tThis generator takes in an extracted set of sequences, output signals,\n",
    "\tand control signals, and will return a single element with random\n",
    "\tjitter and reverse-complement augmentation applied. Jitter is implemented\n",
    "\tefficiently by taking in data that is wider than the in/out windows by\n",
    "\ttwo times the maximum jitter and windows are extracted from that.\n",
    "\tEssentially, if an input window is 1000 and the maximum jitter is 128, one\n",
    "\twould pass in data with a length of 1256 and a length 1000 window would be\n",
    "\textracted starting between position 0 and 256. This  generator must be \n",
    "\twrapped by a PyTorch generator object.\n",
    "\tParameters\n",
    "\t----------\n",
    "\tsequences: torch.tensor, shape=(n, 4, in_window+2*max_jitter)\n",
    "\t\tA one-hot encoded tensor of `n` example sequences, each of input \n",
    "\t\tlength `in_window`. See description above for connection with jitter.\n",
    "\tsignals: torch.tensor, shape=(n, t, out_window+2*max_jitter)\n",
    "\t\tThe signals to predict, usually counts, for `n` examples with\n",
    "\t\t`t` output tasks (usually 2 if stranded, 1 otherwise), each of \n",
    "\t\toutput length `out_window`. See description above for connection \n",
    "\t\twith jitter.\n",
    "\tcontrols: torch.tensor, shape=(n, t, out_window+2*max_jitter) or None, optional\n",
    "\t\tThe control signal to take as input, usually counts, for `n`\n",
    "\t\texamples with `t` strands and output length `out_window`. If\n",
    "\t\tNone, does not return controls.\n",
    "\tin_window: int, optional\n",
    "\t\tThe input window size. Default is 2114.\n",
    "\tout_window: int, optional\n",
    "\t\tThe output window size. Default is 1000.\n",
    "\tmax_jitter: int, optional\n",
    "\t\tThe maximum amount of jitter to add, in either direction, to the\n",
    "\t\tmidpoints that are passed in. Default is 0.\n",
    "\treverse_complement: bool, optional\n",
    "\t\tWhether to reverse complement-augment half of the data. Default is False.\n",
    "\trandom_state: int or None, optional\n",
    "\t\tWhether to use a deterministic seed or not.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself, \n",
    "\t\tsequences, \n",
    "\t\tsignals, \n",
    "\t\tcontrols=None, \n",
    "\t\tin_window=2114, \n",
    "\t\tout_window=1000, \n",
    "\t\tmax_jitter=0, \n",
    "\t\treverse_complement=False, \n",
    "\t\trandom_state=None\n",
    "\t):\n",
    "\t\tself.in_window = in_window\n",
    "\t\tself.out_window = out_window\n",
    "\t\tself.max_jitter = max_jitter\n",
    "\t\t\n",
    "\t\tself.reverse_complement = reverse_complement\n",
    "\t\tself.random_state = np.random.RandomState(random_state)\n",
    "\n",
    "\t\tself.signals = signals\n",
    "\t\tself.controls = controls\n",
    "\t\tself.sequences = sequences\t\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.sequences)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t#i = self.random_state.choice(len(self.sequences))\n",
    "\t\tj = 0 if self.max_jitter == 0 else self.random_state.randint(self.max_jitter*2) \n",
    "\n",
    "\t\tX = self.sequences[idx][:, j:j+self.in_window]\n",
    "\t\ty = self.signals[idx][:, j:j+self.out_window]\n",
    "\n",
    "\t\tif self.controls is not None:\n",
    "\t\t\tX_ctl = self.controls[idx][:, j:j+self.in_window]\n",
    "\n",
    "\t\tif self.reverse_complement and self.random_state.choice(2) == 1:\n",
    "\t\t\tX = torch.flip(X, [0, 1])\n",
    "\t\t\ty = torch.flip(y, [0, 1])\n",
    "\n",
    "\t\t\tif self.controls is not None:\n",
    "\t\t\t\tX_ctl = torch.flip(X_ctl, [0, 1])\n",
    "\n",
    "\t\tif self.controls is not None:\n",
    "\t\t\treturn X, X_ctl, y\n",
    "\n",
    "\t\treturn X, y\n",
    "\t\n",
    "\tdef to_dataloader(\n",
    "\t\tself, \n",
    "        batch_size=None, \n",
    "        pin_memory=True, \n",
    "        shuffle=True, \n",
    "        num_workers=0, \n",
    "        **kwargs\n",
    "    ):\n",
    "\t\t\"\"\"Convert the dataset to a PyTorch DataLoader\n",
    "\n",
    "\t\tParameters:\n",
    "\t\t----------\n",
    "\t\tbatch_size (int, optional):\n",
    "\t\t\tbatch size for dataloader\n",
    "\t\tpin_memory (bool, optional):\n",
    "\t\t\twhether to pin memory for dataloader\n",
    "\t\tshuffle (bool, optional):\n",
    "\t\t\twhether to shuffle the dataset\n",
    "\t\tnum_workers (int, optional):\n",
    "\t\t\tnumber of workers for dataloader\n",
    "\t\t**kwargs:\n",
    "\t\t\tadditional arguments to pass to DataLoader\n",
    "\t\t\"\"\"\n",
    "\t\tbatch_size = batch_size if batch_size is not None else eu.settings.batch_size\n",
    "\t\treturn DataLoader(\n",
    "\t\t\tself,\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tpin_memory=pin_memory,\n",
    "\t\t\tshuffle=shuffle,\n",
    "\t\t\tnum_workers=num_workers,\n",
    "\t\t\t**kwargs\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_dataset = ProfileDataset(\n",
    "    X_toy,\n",
    "    y_toy,\n",
    "    X_ctl_toy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2114]), torch.Size([2, 2114]), torch.Size([2, 1000]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toy_dataset[0][0].shape, toy_dataset[0][1].shape, toy_dataset[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_dataloader = toy_dataset.to_dataloader(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 4, 2114]),\n",
       " torch.Size([100, 2, 2114]),\n",
       " torch.Size([100, 2, 1000]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(toy_dataloader))\n",
    "batch[0].shape, batch[1].shape, batch[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 0.],\n",
       "         [1., 1., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 1., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 1., 0., 1.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpnetlite.io import PeakGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpnetlite_dataloader = PeakGenerator(\n",
    "    peaks,\n",
    "    seqs,\n",
    "    signals,\n",
    "    controls,\n",
    "    max_jitter=0,\n",
    "    batch_size=128,\n",
    "    random_state=13\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 4, 2114]),\n",
       " torch.Size([100, 2, 2114]),\n",
       " torch.Size([100, 2, 1000]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bpnetlite_batch = next(iter(bpnetlite_dataloader))\n",
    "bpnetlite_batch[0].shape, bpnetlite_batch[1].shape, bpnetlite_batch[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 1.,  ..., 0., 1., 0.],\n",
       "         [1., 0., 0.,  ..., 1., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 1., 1.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bpnetlite_batch[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_dev",
   "language": "python",
   "name": "eugene_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
