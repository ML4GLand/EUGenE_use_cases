{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model ready dataset from cisTopic output on `pbmc-granulocyte-sorted-3k_10x-Multiome`\n",
    "Adam Klie (last updated: *09/20/2023*)\n",
    "***\n",
    "This notebook shows how to convert a pycisTopic run into model ready inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyranges as pr\n",
    "from pycisTopic.topic_binarization import binarize_topics, smooth_topics_f\n",
    "from pycisTopic.topic_qc import evaluate_models, compute_topic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define arguments, will be command line\n",
    "data_dir = \"/cellar/users/aklie/data/ml4gland/collabs/er_stress_regulation/test\"\n",
    "dataset_name = \"test\"\n",
    "output_dir = \"/cellar/users/aklie/data/ml4gland/collabs/er_stress_regulation/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cisTopic_obj\n",
    "def load_cisTopic_obj(file_name):\n",
    "    \"\"\"Load a cisTopic object from a pickle file\"\"\"\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        cisTopic_obj = pickle.load(f)\n",
    "    cisTopic_obj.selected_model.topic_ass = {}\n",
    "    return cisTopic_obj\n",
    "cistopic_obj = load_cisTopic_obj(os.path.join(data_dir, dataset_name + \".pycisTopic_obj.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize topics\n",
    "region_bin_topics_otsu = binarize_topics(cistopic_obj, method='otsu', plot=True, num_columns=5, save=os.path.join(output_dir, \"region_topic_binarization.pdf\"))\n",
    "all_regions = cistopic_obj.selected_model.topic_region.index\n",
    "all_regions = all_regions[all_regions.str.contains(\"chr\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_regions_topic_membership(region_dict):\n",
    "    topic_regions_pd = pd.Index([])\n",
    "    topic_regions_lst = []\n",
    "    topic_region_mp = {}\n",
    "    for topic, regions in region_dict.items():\n",
    "        topic_regions_lst += list(regions.index)\n",
    "        topic_regions_pd = pd.Index.union(topic_regions_pd, regions.index)\n",
    "        for region in regions.index:\n",
    "            topic_region_mp.setdefault(region, []).append(topic)\n",
    "    return topic_regions_pd, topic_region_mp, topic_regions_lst\n",
    "topic_regions_pd, topic_region_mp, topic_regions_lst = get_per_regions_topic_membership(region_bin_topics_otsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nontopic_regions(all_regions, topic_regions_pd):\n",
    "    non_topic_regions = all_regions[~all_regions.isin(topic_regions_pd)]\n",
    "    return non_topic_regions\n",
    "non_topic_regions = get_nontopic_regions(all_regions, topic_regions_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binarized_matrix(all_regions, topic_region_mp, n_topics):\n",
    "    arr = np.zeros((len(all_regions), n_topics))\n",
    "    for i, row in enumerate(all_regions):\n",
    "        if row in topic_region_mp:\n",
    "            topic_nums = []\n",
    "            for topic in topic_region_mp[row]:\n",
    "                topic_nums.append(int(topic.split(\"Topic\")[-1])-1)\n",
    "            arr[i, topic_nums] = 1\n",
    "    return arr\n",
    "arr = create_binarized_matrix(all_regions, topic_region_mp, 42)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_topic_binarization(region_dict, arr, all_regions, non_topic_regions, topic_regions_pd, topic_regions_lst):\n",
    "    for topic, regions in region_dict.items():\n",
    "        assert non_topic_regions.isin(regions.index).sum() == 0, f\"Topic {topic} contains a non-topic regions\"\n",
    "    assert np.all(np.array([len(regions) for _, regions in region_dict.items()]) == arr.sum(axis=0)), \"Number of regions per topic does not match the number of 1s in the matrix\"\n",
    "    assert np.all(all_regions[arr.sum(axis=1) == 0].isin(non_topic_regions)), \"Number of regions that are 0 across all topics does not match the number of non-topic regions\"\n",
    "    assert np.all(~all_regions[arr.sum(axis=1) == 0].isin(topic_regions_pd)), \"Number of regions that are not 0 across all topics does not match the number of topic regions\"\n",
    "    assert arr.sum() == len(topic_regions_lst), \"Number of 1s in the matrix does not match the number of topic regions\"\n",
    "check_topic_binarization(region_bin_topics_otsu, arr, all_regions, non_topic_regions, topic_regions_pd, topic_regions_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_seqdata_files(\n",
    "    bin_mtx, \n",
    "    regions, \n",
    "    output_dir, \n",
    "    dataset_name\n",
    "):\n",
    "    region_split = [region.split(\"-\") for region in regions.str.replace(\":\", \"-\")]\n",
    "    region_df = pd.DataFrame(region_split, columns=[\"Chromosome\", \"Start\", \"End\"])\n",
    "    pr_obj = pr.PyRanges(region_df)\n",
    "    seqs = pr.get_fasta(pr_obj, \"/cellar/users/aklie/data/ml4gland/genomes/hg38/hg38.fa\")\n",
    "    np.save(os.path.join(output_dir, dataset_name + \"_labels.npy\"), bin_mtx)\n",
    "    np.save(os.path.join(output_dir, dataset_name + \"_regions.npy\"), regions)\n",
    "    np.save(os.path.join(output_dir, dataset_name + \"_seqs.npy\"), seqs)\n",
    "save_seqdata_files(arr, all_regions, output_dir, dataset_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 scenicplus",
   "language": "python",
   "name": "scenicplus"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
