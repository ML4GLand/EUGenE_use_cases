{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret DeepMEL model using EUGENe on `pbmc-granulocyte-sorted-3k_10x-Multiome`\n",
    "Adam Klie (last updated: *09/20/2023*)\n",
    "***\n",
    "This notebook shows how to interpret a DeepMEL model using EUGENe on the `pbmc-granulocyte-sorted-3k_10x-Multiome` dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tfomics\n",
    "import matplotlib.pyplot as plt\n",
    "import seqdata as sd\n",
    "import seqexplainer as se\n",
    "from eugene import models\n",
    "from eugene.models.zoo import DeepMEL\n",
    "from eugene import plot as pl\n",
    "sys.path.append(\"/Users/adamklie/Desktop/research/projects/ML4GLand/use_cases/DeepMEL/scripts\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up the paths to data (TODO: change to your own paths)\n",
    "dataset_name = \"pbmc-granulocyte-sorted-3k_10x-Multiome\"\n",
    "input_dir = '/cellar/users/aklie/projects/ML4GLand/use_cases/scBasset/pbmc-granulocyte-sorted-3k_10x-Multiome/processed'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test data\n",
    "test_sdata = sd.open_zarr(os.path.join(input_dir, f\"{dataset_name}.test.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the model\n",
    "arch = DeepMEL(\n",
    "    input_len=500, \n",
    "    output_dim=37,\n",
    "    conv_kwargs={\n",
    "        \"conv_channels\": [1024],  \n",
    "    },\n",
    ")\n",
    "model = models.SequenceModule.load_from_checkpoint(\n",
    "    os.path.join(input_dir, dataset_name, \"multiome_cells_all_peaks.DeepMEL.revision/v0/checkpoints/epoch=15-step=16080.ckpt\"),\n",
    "    arch=arch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which topic to interpret\n",
    "topic_num = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run attributions with GradientShap\n",
    "explains = se.attribute(\n",
    "    model,\n",
    "    inputs=torch.tensor(test_sdata[\"ohe_seqs\"].values.transpose(0, 2, 1), dtype=torch.float32),\n",
    "    method=\"GradientShap\",\n",
    "    target=topic_num-1,\n",
    "    reference_type=\"shuffle\",\n",
    "    device=\"cuda\",\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top5 predictions\n",
    "test_preds = model.predict(test_sdata[\"ohe_seqs\"].transpose(\"_sequence\", \"_ohe\", \"length\").values, batch_size=512)\n",
    "test_preds = test_preds.cpu().numpy()\n",
    "top5_ind = np.argsort(test_preds[:, topic_num-1])[::-1][:5]\n",
    "test_preds[top5_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ge the attribution scores for the top5 predictions\n",
    "top5_explains = explains[list(top5_ind)]\n",
    "top5_ind.shape, top5_explains.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_saliency_map(explains, sort, width=13, height_per_explain=1):\n",
    "    \"\"\"\n",
    "    Plot the saliency maps for each sequence\n",
    "    \"\"\"\n",
    "    num_plot = len(explains)\n",
    "    fig = plt.figure(figsize=(width, num_plot*height_per_explain))\n",
    "    for i in range(num_plot):\n",
    "        ax = plt.subplot(num_plot, 1, i+1)\n",
    "        saliency_df = pd.DataFrame(explains[i].transpose([1,0]), columns=[\"A\",\"C\",\"G\",\"T\"])\n",
    "        saliency_df.index.name = \"pos\"\n",
    "        tfomics.impress.plot_attribution_map(saliency_df, ax, figsize=(num_plot,1))\n",
    "        plt.ylabel(sort[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency_map(explains[:5], top5_ind, width=30, height_per_explain=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run modisco\n",
    "pos_patterns, neg_patterns = se.modisco(\n",
    "    one_hot=test_sdata[\"ohe_seq\"].values,\n",
    "    hypothetical_contribs=explains.detach().cpu().numpy(),\n",
    "    input_dir=input_dir,\n",
    "    output_name=f\"DeepSTRESS_30v2_modisco_topic{topic_num}.h5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get modisco logos\n",
    "se.modisco_logos(\n",
    "    modisco_h5_file=os.path.join(input_dir, f\"DeepSTRESS_30v2_modisco_topic{topic_num}.h5\"),\n",
    "    input_dir=os.path.join(input_dir, \"topic1_logos\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modisco report\n",
    "se.modisco_report(\n",
    "    modisco_h5_file=os.path.join(input_dir, f\"DeepSTRESS_30v2_modisco_topic{topic_num}.h5\"),\n",
    "    meme_db_file=\"/cellar/users/aklie/data/shared/meme/motif_databases/HUMAN/HOCOMOCOv11_core_HUMAN_mono_meme_format.meme\",\n",
    "    input_dir=os.path.join(input_dir, \"report\"),\n",
    "    top_n_matches=2,\n",
    "    trim_threshold=0.3,\n",
    "    trim_min_length=3,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
