{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zenodo DeepSTARR model evaluation\n",
    "Adam Klie (last updated: *09/20/2023*)\n",
    "***\n",
    "Notebook for evaluating DeepSTARR model on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plot the predictions in a scatter plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "# Add metrics to the plots\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keras_model(path):\n",
    "    from keras.models import model_from_json\n",
    "    model = model_from_json(open(path + '.json').read())\n",
    "    model.load_weights(path + '.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_keras_model(\"/cellar/users/aklie/projects/ML4GLand/use_cases/deAlmeida22/models/zenodo/DeepSTARR.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fastas_from_file(fasta_path, as_dict=False,\n",
    "                         uppercase=False, stop_at=None):\n",
    "    fastas = []\n",
    "    seq = None\n",
    "    header = None\n",
    "    for r in (gzip.open(fasta_path) if fasta_path.endswith(\".gz\") else open(fasta_path)):\n",
    "        if type(r) is bytes:\n",
    "            r = r.decode(\"utf-8\")\n",
    "        r = r.strip()\n",
    "        if r.startswith(\">\"):\n",
    "            if seq != None and header != None:\n",
    "                fastas.append([header, seq])\n",
    "                if stop_at != None and len(fastas) >= stop_at:\n",
    "                    break\n",
    "            seq = \"\"\n",
    "            header = r[1:]\n",
    "        else:\n",
    "            if seq != None:\n",
    "                seq += r.upper() if uppercase else r\n",
    "            else:\n",
    "                seq = r.upper() if uppercase else r\n",
    "    # append last fasta read by method\n",
    "    if stop_at != None and len(fastas) < stop_at:\n",
    "        fastas.append([header, seq])\n",
    "    elif stop_at == None:\n",
    "        fastas.append([header, seq])\n",
    "    if as_dict:\n",
    "        return {h: s for h, s in fastas}\n",
    "\n",
    "    return pd.DataFrame({'location': [e[0] for e in fastas], 'sequence': [e[1] for e in fastas]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_df = get_fastas_from_file(\"/cellar/users/aklie/projects/ML4GLand/use_cases/deAlmeida22/data/Sequences_Test.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_alpha_to_seq(sequence):\n",
    "    output = np.arange(len(sequence))\n",
    "    for i in range(0, len(sequence)):\n",
    "        snippet = sequence[i]\n",
    "        if snippet == 'A':\n",
    "            output[i] = 0\n",
    "        elif snippet == 'C':\n",
    "            output[i] = 1\n",
    "        elif snippet == 'G':\n",
    "            output[i] = 2\n",
    "        elif snippet == 'T':\n",
    "            output[i] = 3\n",
    "        elif snippet == 'N':\n",
    "            output[i] = -1\n",
    "        else:\n",
    "            raise AssertionError(\"Cannot handle snippet: \" + snippet)\n",
    "    return output\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    '''Convert class vector (integers from 0 to nb_classes)\n",
    "    to binary class matrix, for use with categorical_crossentropy\n",
    "    '''\n",
    "    y = np.asarray(y, dtype='int32')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y) + 1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        if y[i] != -1:\n",
    "            Y[i, y[i]] = 1.\n",
    "    return Y\n",
    "\n",
    "def do_one_hot_encoding(sequence, seq_length, f=parse_alpha_to_seq):\n",
    "    X = np.zeros((sequence.shape[0], seq_length, 4))\n",
    "    for idx in range(0, len(sequence)):\n",
    "        X[idx] = to_categorical(f(sequence[idx]), 4)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of first sequence\n",
    "sequence_length = len(fasta_df.sequence.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequence to one hot encoding matrix\n",
    "seq_matrix = do_one_hot_encoding(fasta_df.sequence, sequence_length, parse_alpha_to_seq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(seq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prediction = fasta_df\n",
    "out_prediction['Predictions_dev'] = preds[0]\n",
    "out_prediction['Predictions_hk'] = preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv(\"/cellar/users/aklie/projects/ML4GLand/use_cases/deAlmeida22/data/Sequences_activity_Test.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prediction[[\"True_dev\", \"True_hk\"]] = targets[['Dev_log2_enrichment_scaled', 'Hk_log2_enrichment_scaled']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Get point densities\n",
    "x = out_prediction['True_dev']\n",
    "y = out_prediction['Predictions_dev']\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "ax[0].scatter(x, y, c=z)\n",
    "\n",
    "# Get point densities\n",
    "x = out_prediction['True_hk']\n",
    "y = out_prediction['Predictions_hk']\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "ax[1].scatter(x, y, c=z)\n",
    "\n",
    "r2_dev = r2_score(out_prediction['True_dev'], out_prediction['Predictions_dev'])\n",
    "r2_hk = r2_score(out_prediction['True_hk'], out_prediction['Predictions_hk'])\n",
    "\n",
    "pearson_dev = pearsonr(out_prediction['True_dev'], out_prediction['Predictions_dev'])\n",
    "pearson_hk = pearsonr(out_prediction['True_hk'], out_prediction['Predictions_hk'])\n",
    "\n",
    "spearman_dev = spearmanr(out_prediction['True_dev'], out_prediction['Predictions_dev'])\n",
    "spearman_hk = spearmanr(out_prediction['True_hk'], out_prediction['Predictions_hk'])\n",
    "\n",
    "ax[0].set_title(f\"Dev R2: {r2_dev:.2f}\\nPearson: {pearson_dev[0]:.2f}\\nSpearman: {spearman_dev[0]:.2f}\")\n",
    "ax[1].set_title(f\"Hk R2: {r2_hk:.2f}\\nPearson: {pearson_hk[0]:.2f}\\nSpearman: {spearman_hk[0]:.2f}\")\n",
    "\n",
    "# Add a diagonal line to the plots\n",
    "ax[0].plot(ax[0].get_xlim(), ax[0].get_ylim(), ls=\"--\", c=\".3\")\n",
    "ax[1].plot(ax[1].get_xlim(), ax[1].get_ylim(), ls=\"--\", c=\".3\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again tried to make this work, seems to run into dependency hell with Keras. Seems like you need to make sure the version of Keras that the model is trained with is also what you try to run the following with. This requires an environment for every different model, which is less than ideal\n",
    "\n",
    "```python\n",
    "TypeError: Keras symbolic inputs/outputs do not implement `op`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from deeplift.dinuc_shuffle import dinuc_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(seq_matrix) # Replace NaN with zero and infinity with large finite numbers\n",
    "X_reshaped = X.reshape((X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinuc_shuffle_n=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dinuc_shuffle_several_times(list_containing_input_modes_for_an_example,\n",
    "                                seed=1234):\n",
    "  assert len(list_containing_input_modes_for_an_example)==1\n",
    "  onehot_seq = list_containing_input_modes_for_an_example[0]\n",
    "  rng = np.random.RandomState(seed)\n",
    "  to_return = np.array([dinuc_shuffle(onehot_seq, rng=rng) for i in range(dinuc_shuffle_n)])\n",
    "  return [to_return] #wrap in list for compatibility with multiple modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hypothetical scores also\n",
    "def combine_mult_and_diffref(mult, orig_inp, bg_data):\n",
    "    assert len(orig_inp)==1\n",
    "    projected_hypothetical_contribs = np.zeros_like(bg_data[0]).astype(\"float\")\n",
    "    assert len(orig_inp[0].shape)==2\n",
    "    #At each position in the input sequence, we iterate over the one-hot encoding\n",
    "    # possibilities (eg: for genomic sequence, this is ACGT i.e.\n",
    "    # 1000, 0100, 0010 and 0001) and compute the hypothetical\n",
    "    # difference-from-reference in each case. We then multiply the hypothetical\n",
    "    # differences-from-reference with the multipliers to get the hypothetical contributions.\n",
    "    #For each of the one-hot encoding possibilities,\n",
    "    # the hypothetical contributions are then summed across the ACGT axis to estimate\n",
    "    # the total hypothetical contribution of each position. This per-position hypothetical\n",
    "    # contribution is then assigned (\"projected\") onto whichever base was present in the\n",
    "    # hypothetical sequence.\n",
    "    #The reason this is a fast estimate of what the importance scores *would* look\n",
    "    # like if different bases were present in the underlying sequence is that\n",
    "    # the multipliers are computed once using the original sequence, and are not\n",
    "    # computed again for each hypothetical sequence.\n",
    "    for i in range(orig_inp[0].shape[-1]):\n",
    "        hypothetical_input = np.zeros_like(orig_inp[0]).astype(\"float\")\n",
    "        hypothetical_input[:,i] = 1.0\n",
    "        hypothetical_difference_from_reference = (hypothetical_input[None,:,:]-bg_data[0])\n",
    "        hypothetical_contribs = hypothetical_difference_from_reference*mult[0]\n",
    "        projected_hypothetical_contribs[:,:,i] = np.sum(hypothetical_contribs,axis=-1)\n",
    "    return [np.mean(projected_hypothetical_contribs,axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(\n",
    "    (model.layers[0].input, model.layers[-1].output),\n",
    "    data=dinuc_shuffle_several_times,\n",
    "    combine_mult_and_diffref=combine_mult_and_diffref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_hypothetical = explainer.shap_values(one_hot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 eugene_dev",
   "language": "python",
   "name": "eugene_dev"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
